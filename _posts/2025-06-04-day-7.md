---
layout: post
title: "Day 7 â€“ Deep Learning, Computer Vision, and Literature Review"
date: 2025-06-04
author: Yusrat Miah
permalink: /day7.html
tags: ["Deep Learning", "Computer Vision", "APA7", "Literature Review"]

what_i_learned: |
  I continued the work that I stared earlier this week. Specifically, I completed the Intro to Deep Learning course on Kaggle. The Deep Learning Kaggle course finished off by explaining how binary classification works. Binary classification is the computers way of using 0 or 1 to label to the two possible outcomes (i.e. yes or no, dog or cat), when trying make an accurate predication. Probability is utlized in binary classification as a higher value represents a higher confidence rate that its in the correct class. An activiation function in neural networks is what transforms a real-valued input into a value between 0 and 1.0.
  Next, I transitioned into making progress towards completing the Computer Vision (CV) course on Kaggle, which brings together all the concepts that I learned in the Machine Learning and Deep Learning Kaggle courses. Today, I finised 3 out of the 6 modules for the CV course: The Convolutional Classifier, Convolition and ReLU, and Maximum Pooling. I especially liked learning about Maximum Pooling as this technique can help reduce the need to iteratively analyze the image frequently and rather simplifies the process by simplifing the feature map into a "pooled" feature map, which helps signifiy various components of an image. 
  Lastly, I started writing my Literature Review paper in APA format. The Literature Review paper is important as it will summarize the importance of the research question on hand, explain the potential methodolgies, and highlight the strenghts and weaknesses of each of the journal papers that I read over the week. I also explored the Driver Drowsiness Detection GoogleColab code and ran it on my end. It was cool to see all the epochs running and learning that it takes time and GPU power to run the models.

blockers: |
  I wanted to gain further insight on Convoltion, ReLU, and Maxpooling, so I watched short 10 minute lectures on these topics.
  
reflection: |
  Learning how the computer "sees" through layers of neural networks was eye-opening for me. It helped me grasp the importance of deep learning algorithms and why it is so important to learn about the various models. I hope to do further research on the Mobilenetv2, Densenet121, and EfficeintB0 models to possibly utilize them for the predictive model that my project group will build. My goal for tomorrow is to finish up the Computer Vision Course on Kaggle and finish writing my draft for my literature review.
---


