---
layout: post
title: "Day 8 – Campus Tour, Computer Vision Course, Literature Review"
date: 2025-06-05
author: Yusrat Miah
permalink: /day8.html
tags: ["Community Building", "Computer Vision", "Feature Extraction", "Custom Convnets"]

what_i_learned: |
  The day began with a collective group campus tour of Morgan State University. Throughout the tour, I was able to see the modern facilities, hear more about opportunities, and meet new people within the CEAMLES SAIRI cohort. I found the campus itself to be very inviting to students. The notable part of the tour was discovering the rather sceanic trail that goes from the area of Holmes Hall all the way to the Center of Built Environment & Infrastructure Studies. I mention this because the lab I work for is located in the Center of Built Environment & Infrastructure Studies, which is quite a walk from the center of campus. I also interacted with members from the Project 7 and Project 8 during the lunch break after discovering that their office across the floor of the building I sit in. After the lunch break, I went back to the lab and continued to make progress on finishing my Computer Vision course on Kaggle, writing my literature review, and creating my slide for the video presentation due tomorrow. Through the Computer Vision course today, I learned about sliding windows, which is able to capture more detailed patterns of an image through processing overlapping sections that are smaller in size. I was able to finish my slide for the video presentation and complete two pages out of the four pages for my literature review. 

  This helped me better understand how attention levels fluctuate, especially when switching between tasks. I also learned how to calculate moving averages to reduce noise in the signal while preserving response time.

blockers: |
  I do need to continuously review Computer Vision terminology. Therefore, I plan on making a Quizlet with vocabulary relating to the subject area on hand.

reflection: |
  Watching my brainwaves animate in real time felt surreal. It made all the previous setup work worth it. Next, I’ll begin connecting this live data stream to robotic behaviors in NeuroLink Assist—starting with simple directional movement based on concentration strength.
---
