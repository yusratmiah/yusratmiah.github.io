---
layout: post
title: "Day 11 â€“ MobileNetV2, Efficientnet, and Running Different Models "
date: 2025-06-10
author: Yusrat Miah
permalink: /day11.html
tags: ["Machine Learning", "CNN architectures", "MobileNetV2", "TensorFlow", "Efficientnet"]

what_i_learned: |
  I began my day by watching and taking notes on the MobileNetV2 video series that I have been watching on YouTube. Through this, I learned that the key differences between MobileNetV1 and MobileNetV2 is that MobileNetV2 utilizes the technique of inverted residuals with linear bottlenecks, which makes it faster since the differen activations are low dimensional and since the point-wise convulation compresses the data. Then, I transitioned to solidifying my knowledge on MobileNets and EfficientNet models by starting a LinkedinLearning course titled "Computer Vision for Data Scientists." Through this course, I have been able to gain a fresh prespective on the evolution of CNN architectures. 
  Later in the day, I transitioned into writing a summary about MobileNetV1 & V2, Densenet121, Efficient B0 V1 & V2. I also ran each of the models on the codebases that was given to us. I plan on analyzing the data and adding my thoughts to the summary report that I am currently developing.

blockers: |
  It did take some time running the models since I ran all the models on an epoch of 10 on Google Colab. 

reflection: |
  I would say today was a normal day in the lab and nothing really exciting happended. I realized I should allocate time to dedicately read scholarly articles and maybe start my day with them. By doing this, it will help me add on to my current techinical writing pieces and allow me to be a better reader. Tomorrow's goal is make more progress on my summary article.
---

